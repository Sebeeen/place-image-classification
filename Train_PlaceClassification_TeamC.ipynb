{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "패턴인식과머신러닝 Team Project Team C\n",
        "\n",
        "1970014 김세빈\n",
        "\n",
        "1970062 이서린\n",
        "\n",
        "2070020 김정연\n",
        "\n",
        "2070087 최지인"
      ],
      "metadata": {
        "id": "fL5GD7rLufvV"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usk6mAXnj82w"
      },
      "source": [
        "## 1. Import Library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gkr3F-VzQlrq"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "import albumentations as albu\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms, models\n",
        "\n",
        "from torch.autograd import Variable\n",
        "import torch.utils.data as data\n",
        "import pandas as pd\n",
        "import os\n",
        "from PIL import Image\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "import sklearn.model_selection as sk\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-GObD3yj828"
      },
      "source": [
        "## 2. Import Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1uOfJMhdDiZ",
        "outputId": "d5c862a8-1fbb-41bd-8df8-e26c0a7b9a89"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# ######### 코랩 환경 ##########\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Dataset path load\n",
        "train_path = '/content/drive/MyDrive/패턴/TrainData/Train'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For least randomness, fix seed as 7"
      ],
      "metadata": {
        "id": "H0I-EV0xOUHm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "IBuUs-16l5vu"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "seed = 7\n",
        "deterministic = True\n",
        "\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nifFHZe3j829"
      },
      "source": [
        "## 3. Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3.1 Image Normalization, Data split"
      ],
      "metadata": {
        "id": "IA9RiZO1-oXa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Load\n",
        "classes = ['campus', 'farm', 'train_station']  #campus:0, farm:1, train_station:2\n",
        "\n",
        "data=[]\n",
        "label=[]\n",
        "\n",
        "## i : Integer representation for each classes (campus/farm/train_station -> 0/1/2)\n",
        "for i,d in enumerate(classes):\n",
        "    files = os.listdir(train_path+'/'+d)\n",
        "    \n",
        "    for f in files:\n",
        "        img = Image.open(train_path+'/'+d+'/'+f)\n",
        "        \n",
        "        # Data normalization\n",
        "        one_img = np.asarray(np.float32(img))\n",
        "        norm_img = one_img/255.0\n",
        "\n",
        "        img = np.asarray([norm_img])\n",
        "        data.append(img)\n",
        "        label.append(i)\n",
        "        \n",
        "data = np.array(data, dtype='float32')\n",
        "label = np.array(label, dtype='int64')\n",
        "\n",
        "total_X = torch.from_numpy(data)\n",
        "total_Y = torch.from_numpy(label)"
      ],
      "metadata": {
        "id": "BLypx48yCLQ3"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "class별 3000장 균등 분배 확인, train data를 2배 증식할 것이기 때문에\n",
        "\n",
        " 각 class 별 train 2000장 : test 1000장으로 data split을 해 train을 4000장으로 늘릴 예정. \n",
        " \n",
        " 따라서 data split에 test data 비율 0.333 적용.\n",
        "\n",
        " 각 class별 train 2000장, test 1000장이므로 전체는 6000:3000장"
      ],
      "metadata": {
        "id": "QS6zhaRgDOID"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#checking class\n",
        "df1=pd.DataFrame(total_Y.numpy())\n",
        "\n",
        "zero=0\n",
        "one=0\n",
        "two=0\n",
        "for i in range(len(df1)):\n",
        "  if int(df1.iloc[i])==0:\n",
        "    zero+=1\n",
        "  if int(df1.iloc[i])==1:\n",
        "    one+=1\n",
        "  if int(df1.iloc[i])==2:\n",
        "    two+=1\n",
        "print('Campus class 데이터 수 :', zero)\n",
        "print('Farm class 데이터 수 :', one)\n",
        "print('Train station 데이터 수 :', two)\n",
        "\n",
        "# Dataset split\n",
        "X_train, X_valid, Y_train, Y_valid = sk.train_test_split(total_X, total_Y, test_size=0.33333, random_state=100, stratify=total_Y)\n",
        "print(X_train.shape, X_valid.shape, Y_train.shape, Y_valid.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYHKvYpMBS6D",
        "outputId": "30db0f0c-102f-4fb2-ad0e-78b8fb16492b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Campus class 데이터 수 : 3000\n",
            "Farm class 데이터 수 : 3008\n",
            "Train station 데이터 수 : 3000\n",
            "torch.Size([6005, 1, 100, 100]) torch.Size([3003, 1, 100, 100]) torch.Size([6005]) torch.Size([3003])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3.2 Augmentation"
      ],
      "metadata": {
        "id": "gfMkF9oSO1S1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3.2.1 Data Augmentation"
      ],
      "metadata": {
        "id": "kqTyHOSKO6UW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train dataset Horizontal flip"
      ],
      "metadata": {
        "id": "XvblKm1nE3nN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "flip = transforms.RandomHorizontalFlip(p=1)\n",
        "X_train_aug=flip(X_train)\n",
        "X_train_new=torch.concat((X_train, X_train_aug), dim=0)\n",
        "Y_train_new=torch.concat((Y_train,Y_train),dim=0)\n",
        "\n",
        "print(X_train_new.shape, X_valid.shape, Y_train_new.shape, Y_valid.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8tUCddAJB_69",
        "outputId": "6aa969f8-ff9f-4167-f5e4-516869d290fd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([12010, 1, 100, 100]) torch.Size([3003, 1, 100, 100]) torch.Size([12010]) torch.Size([3003])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RandomChoice"
      ],
      "metadata": {
        "id": "EEeZu3FaX3dv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Ys8Vt4UmwMWE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3.2.2 Image Augmentation"
      ],
      "metadata": {
        "id": "rUAr8sXaPAEP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "h7hfEYs9j82_"
      },
      "outputs": [],
      "source": [
        "class Custom_dataset(Dataset):\n",
        "    def __init__(self, img_paths, labels, mode='train'):\n",
        "        self.img_paths = img_paths\n",
        "        self.labels = labels\n",
        "        self.mode = mode\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        img = self.img_paths[idx]\n",
        "        if self.mode=='train':\n",
        "            img = train_transform(image=img)\n",
        "        \n",
        "        if self.mode=='test':\n",
        "            img = test_transform(image=img)\n",
        "        \n",
        "        label = self.labels[idx]\n",
        "        return img, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "aSCJL5iQj82_"
      },
      "outputs": [],
      "source": [
        "train_transform = albu.Compose([\n",
        "    albu.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n",
        "    albu.OneOf([\n",
        "        albu.MotionBlur(p=0.2),\n",
        "        albu.MedianBlur(blur_limit=3, p=0.1),\n",
        "        albu.Blur(blur_limit=3, p=0.1),\n",
        "    ], p=0.2),\n",
        "])\n",
        "\n",
        "# No transformation added to test(validation) dataset\n",
        "test_transform = albu.Compose([\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DataLoader\n",
        "train_dataset = Custom_dataset(np.array(X_train_new),np.array(Y_train_new), mode='train')\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "valid_dataset = Custom_dataset(np.array(X_valid),np.array(Y_valid), mode='test')\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "9w6Lem99_YIK"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWy1igjuLh-t",
        "outputId": "8194e997-bb46-48bb-f9cb-898cd020c09d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Campus class 데이터 수 : 4000\n",
            "Farm class 데이터 수 : 4010\n",
            "Train station 데이터 수 : 4000\n"
          ]
        }
      ],
      "source": [
        "#Checking whether augmentation is done well and image dataset are  i\n",
        "\n",
        "newdf=pd.DataFrame(Y_train_new.numpy())\n",
        "\n",
        "zero=0\n",
        "one=0\n",
        "two=0\n",
        "for i in range(len(newdf)):\n",
        "  if int(newdf.iloc[i])==0:\n",
        "    zero+=1\n",
        "  if int(newdf.iloc[i])==1:\n",
        "    one+=1\n",
        "  if int(newdf.iloc[i])==2:\n",
        "    two+=1\n",
        "print('Campus class 데이터 수 :', zero)\n",
        "print('Farm class 데이터 수 :', one)\n",
        "print('Train station 데이터 수 :', two)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Mq616n5j83A"
      },
      "source": [
        "## 4. Define Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lHm5UFZej83B",
        "outputId": "0a26816a-cfbb-4179-fe13-0e0f5a32303a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (conv): Sequential(\n",
              "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): ReLU()\n",
              "    (6): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (7): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (8): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (9): ReLU()\n",
              "    (10): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (11): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (12): ReLU()\n",
              "    (13): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (14): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (15): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (16): ReLU()\n",
              "    (17): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (18): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (19): ReLU()\n",
              "    (20): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (fc): Sequential(\n",
              "    (0): Linear(in_features=4096, out_features=256, bias=True)\n",
              "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): Dropout(p=0.3, inplace=False)\n",
              "    (4): Linear(in_features=256, out_features=128, bias=True)\n",
              "    (5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (6): ReLU()\n",
              "    (7): Dropout(p=0.3, inplace=False)\n",
              "    (8): Linear(in_features=128, out_features=3, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            \n",
        "            nn.Conv2d(1, 16, 3),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "            \n",
        "            nn.Conv2d(16, 16, 3),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "            \n",
        "            nn.MaxPool2d(3,2),\n",
        "            \n",
        "            nn.Conv2d(16, 32, 3),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv2d(32, 32, 3),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            \n",
        "            nn.MaxPool2d(3,2),\n",
        "            \n",
        "            nn.Conv2d(32, 64, 3),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            \n",
        "            nn.Conv2d(64, 64, 3),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            \n",
        "            nn.MaxPool2d(3,2),\n",
        "\n",
        "        )\n",
        "        \n",
        "  \n",
        "        self.fc = nn.Sequential(\n",
        "                nn.Linear(4096, 256),\n",
        "                nn.BatchNorm1d(256),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(p=0.3),\n",
        "                nn.Linear(256, 128),\n",
        "                nn.BatchNorm1d(128),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(p=0.3),\n",
        "                nn.Linear(128, 3)\n",
        "                \n",
        "\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = x.view(x.size(0),-1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "model = Net()\n",
        "model.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "JP9zbke6gLBL"
      },
      "outputs": [],
      "source": [
        "def run_train(model):\n",
        "    model.train()\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.NAdam(model.parameters(), lr=0.001)\n",
        "    \n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    incorrect = 0\n",
        "    \n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs['image'].type(torch.cuda.FloatTensor), labels.type(torch.cuda.LongTensor)\n",
        "        inputs, labels = Variable(inputs), Variable(labels)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(inputs)\n",
        "        \n",
        "        loss = criterion(output, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.data.item()\n",
        "\n",
        "        idx, pred = output.max(1)\n",
        "        pred = (pred.detach().cpu().numpy())\n",
        "        truth = (labels.detach().cpu().numpy())\n",
        "        \n",
        "        for ix in range(len(pred)):\n",
        "            if pred[ix] == truth[ix]:\n",
        "                correct = correct +1\n",
        "            else:\n",
        "                incorrect = incorrect +1\n",
        "        accuracy = (correct/(correct+incorrect))*100\n",
        "        train_img = inputs.cpu().numpy()\n",
        "        \n",
        "    return train_img, pred, truth, accuracy, total_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "e6j5TpFxgmib"
      },
      "outputs": [],
      "source": [
        "def run_valid(model):\n",
        "    model.eval()\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    \n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    incorrect = 0\n",
        "    \n",
        "    for inputs, labels in valid_loader:\n",
        "        inputs, labels = inputs['image'].type(torch.cuda.FloatTensor), labels.type(torch.cuda.LongTensor)\n",
        "        inputs, labels = Variable(inputs), Variable(labels)\n",
        "\n",
        "        output = model(inputs)\n",
        "        idx, pred = output.max(1)\n",
        "        pred = (pred.detach().cpu().numpy())\n",
        "        truth = (labels.detach().cpu().numpy())\n",
        "\n",
        "        \n",
        "        loss = criterion(output, labels)\n",
        "        total_loss += loss.data.item()\n",
        "        \n",
        "        for ix in range(len(pred)):\n",
        "            if pred[ix] == truth[ix]:\n",
        "                correct = correct +1\n",
        "            else:\n",
        "                incorrect = incorrect +1\n",
        "        accuracy = (correct/(correct+incorrect))*100\n",
        "        valid_img = inputs.cpu().numpy()\n",
        "        \n",
        "    return valid_img, pred, truth, accuracy, total_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eeJC1RqcWxno"
      },
      "source": [
        "## 5. Train Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "acc_t = []\n",
        "acc_v = []\n",
        "\n",
        "\n",
        "epoch = 100\n",
        "print('***START EPOCH***')\n",
        "\n",
        "for E in range(1, epoch+1):\n",
        "    print(f'# Epoch : {E} /{epoch}')\n",
        "    train_img, pred_t, truth_t, accuracy_t, loss_t = run_train(model)\n",
        "    valid_img, pred_v, truth_v, accuracy_v, loss_v = run_valid(model)\n",
        "    \n",
        "    print('Train Accuracy : {}'.format(accuracy_t))\n",
        "    print('Validation Accuracy : {}'.format(accuracy_v))\n",
        "    acc_t.append(accuracy_t)\n",
        "    acc_v.append(accuracy_v)\n",
        "'''\n",
        "\n",
        "loss_t = []\n",
        "loss_v = []\n",
        "acc_t = []\n",
        "acc_v = []\n",
        "\n",
        "epoch = 100\n",
        "print('***START EPOCH***')\n",
        "\n",
        "for E in range(1, epoch+1):\n",
        "    print(f'# Epoch : {E} /{epoch}')\n",
        "    train_img, pred_t, truth_t, accuracy_t, loss_train = run_train(model)\n",
        "    valid_img, pred_v, truth_v, accuracy_v, loss_valid = run_valid(model)\n",
        "    \n",
        "    print('Train Accuracy : {}'.format(accuracy_t))\n",
        "    print('Validation Accuracy : {}'.format(accuracy_v))\n",
        "    \n",
        "    loss_t.append(loss_train)\n",
        "    loss_v.append(loss_valid)\n",
        "    acc_t.append(accuracy_t)\n",
        "    acc_v.append(accuracy_v)"
      ],
      "metadata": {
        "id": "zjPzywS4Wxno"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 시각화\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "# 정확도 그래프\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(range(len(acc_t)), acc_t, 'b', range(len(acc_v)), acc_v, 'r')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Train and Validation Accuracy')\n",
        "blue_patch = mpatches.Patch(color='blue', label='Train Accuracy')\n",
        "red_patch = mpatches.Patch(color='red', label='Validation Accuracy')\n",
        "plt.legend(handles=[red_patch, blue_patch])\n",
        "\n",
        "# 손실 함수 그래프\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(range(len(loss_t)), loss_t, 'b', range(len(loss_v)), loss_v, 'r')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Train and Validation Loss')\n",
        "blue_patch = mpatches.Patch(color='blue', label='Train Loss')\n",
        "red_patch = mpatches.Patch(color='red', label='Validation Loss')\n",
        "plt.legend(handles=[red_patch, blue_patch])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qSMrXeGSWxnp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51znXq4aj83D"
      },
      "source": [
        "## 6. Save Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "########## 코랩 환경 ##########\n",
        "\n",
        "# Save the weight matrices and bias vectors that will be loaded for testing later\n",
        "torch.save(model,'/content/drive/MyDrive/패턴/TeamC')"
      ],
      "metadata": {
        "id": "MORKGstuMBfv"
      },
      "execution_count": 46,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}